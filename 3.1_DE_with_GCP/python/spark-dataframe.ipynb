{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae10115",
   "metadata": {},
   "source": [
    "# Spark Basic Syntax Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c3744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f54f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required if at some point you got \n",
    "# 'java.io.IOException: Cannot run program \"python3\": CreateProcess error=2, The system cannot find the file specified'\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1182e163",
   "metadata": {},
   "source": [
    "Open spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33941a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Spark Dataframe\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3c04d7",
   "metadata": {},
   "source": [
    "Build dataframe from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7935d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/spark_loan.jsonl\"\n",
    "loan_df = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbb8604",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4eed9f",
   "metadata": {},
   "source": [
    "Print schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d774ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759a3d4e",
   "metadata": {},
   "source": [
    "Count the data frame rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecb5fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee1b14f",
   "metadata": {},
   "source": [
    "Describe all fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e751a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689bea4f",
   "metadata": {},
   "source": [
    "These two lines is to eliminite line break for text wrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fcc207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0c0766",
   "metadata": {},
   "source": [
    "Or, just select few fields to describe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ab2b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.describe(\"full_name\", \"loan_amount\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fed883",
   "metadata": {},
   "source": [
    "Drop duplicates, and show the distinct records, ordered by certain field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987ac2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.select(\"payment_period\", \"loan_period_weeks\").drop_duplicates().sort(\"payment_period\", \"loan_period_weeks\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2e0850",
   "metadata": {},
   "source": [
    "Collect all data into local python memory. Careful, if the data is very large, this might trigger an out-of-memory error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4c5fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7faae58",
   "metadata": {},
   "source": [
    "Alternatively, just take the first *n* data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3331507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df439d5f",
   "metadata": {},
   "source": [
    "Or, the last *n* data.\n",
    "  \n",
    "**Note:** Running `tail` will move data into the local machine, so very large num can cause out-of-memory error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0029b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5c4422",
   "metadata": {},
   "source": [
    "Pyspark DataFrame also provides the conversion to pandas DataFrame to leverage pandas APIs.  \n",
    "\n",
    "**Note** : `toPandas` will collects all data into the local python, which can cause an out-of-memory-error when the data is too large to fit into one machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d39f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_loan_df = loan_df.toPandas()\n",
    "pandas_loan_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714270f7",
   "metadata": {},
   "source": [
    "Accessing column can be done using several ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af034a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_loan_id = loan_df.loan_id\n",
    "col_full_name = loan_df[\"full_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a9b98d",
   "metadata": {},
   "source": [
    "Selecting column from data frame.  \n",
    "\n",
    "By default, spark will truncate long values. So we use optional parameter `truncate` to show un-truncated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d59cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.select(col_loan_id, col_full_name, loan_df.loan_amount, loan_df[\"loan_approved_date\"]).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0334df1b",
   "metadata": {},
   "source": [
    "Filtering data, show only loan amount between 500-700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65345323",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.filter( (loan_df.loan_amount >= 500) & (loan_df.loan_amount <= 700) ).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e23fa08",
   "metadata": {},
   "source": [
    "Or, filtering using SQL-like syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17796536",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.filter( \"loan_amount < 500 OR loan_amount > 700\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a094caf",
   "metadata": {},
   "source": [
    "Pyspark provides `where()` as an alias to `filter()`.  \n",
    "The example below also sort the filtered rows by loan_amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d92f250",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.where( (loan_df.loan_amount >= 500) & (loan_df.loan_amount <= 700) ).sort(loan_df.loan_amount).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f832a1",
   "metadata": {},
   "source": [
    "Sort descending. Spark also provides `orderBy()` as alias to `sort()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72934bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.where( \"loan_amount < 500 OR loan_amount > 700\").orderBy(\"loan_amount\", ascending=False).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f52d5b2",
   "metadata": {},
   "source": [
    "Sort by multiple columns & ascending / descending. For example, sort by `loan_approved_date` (ascending), then by `loan_amount` (descending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53950aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.orderBy([\"loan_approved_date\", \"loan_amount\"], ascending=[True, False]).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411ebccf",
   "metadata": {},
   "source": [
    "## Grouping & Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e363c7",
   "metadata": {},
   "source": [
    "Several built-in aggregation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b49fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in loan_df.groupby(\"loan_rating\").count().orderBy(\"loan_rating\").collect():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de9fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in loan_df.groupby(\"payment_period\").avg(\"loan_amount\").orderBy(\"payment_period\").collect():\n",
    "    print(\"Payment period {} has average loan amount {}\".format(row[0], row[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab589334",
   "metadata": {},
   "source": [
    "## UDF (User-Defined-Function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f6a663",
   "metadata": {},
   "source": [
    "Calculate and create new column `loan_end_date` based on user-defined-function \n",
    "(`udf`) with formula \n",
    "\n",
    "`loan_end_date = loan_approved_date + loan_period_weeks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efe86bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_loan_end_date = udf(lambda x, y: (datetime.fromisoformat(x) + timedelta(weeks=y)).strftime('%Y-%m-%d') )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adcb435",
   "metadata": {},
   "source": [
    "Put into new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da65ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_udf = loan_df.withColumn(\"loan_end_date\", get_loan_end_date(loan_df.loan_approved_date, loan_df.loan_period_weeks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d79b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_udf.select(\"loan_id\", \"loan_approved_date\", \"loan_period_weeks\", \"loan_end_date\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a839f1",
   "metadata": {},
   "source": [
    "UDF using function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7297b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def just_repeat(str):\n",
    "    if random.choice([True, False]):\n",
    "        return str + \" & \" + str\n",
    "    else:\n",
    "        return str + \" & \" + str + \" & \" + str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d307f2e4",
   "metadata": {},
   "source": [
    "Need to register the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f9440",
   "metadata": {},
   "outputs": [],
   "source": [
    "just_repeat_udf = spark.udf.register(\"just_repeat\", just_repeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4569794c",
   "metadata": {},
   "source": [
    "Then, use the registered UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20319580",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_udf_repeat = loan_df.select(\"full_name\").withColumn(\n",
    "    \"justRepeatingColumn\", just_repeat_udf(loan_df.full_name)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee1d585",
   "metadata": {},
   "source": [
    "## API Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb8969",
   "metadata": {},
   "source": [
    "Spark dataframe API reference [available here](http://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#dataframe-apis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
